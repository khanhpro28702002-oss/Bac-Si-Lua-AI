import streamlit as st
from inference_sdk import InferenceHTTPClient
from PIL import Image, ImageDraw, ImageFont
import numpy as np
import cv2
from datetime import datetime
from gtts import gTTS
import requests
from streamlit_js_eval import get_geolocation
import google.generativeai as genai
import os
from dotenv import load_dotenv

# CONFIG GEMINI
load_dotenv()
genai.configure(api_key=os.getenv("GOOGLE_API_KEY"))
model = genai.GenerativeModel('gemini-1.5-flash')

st.set_page_config(page_title="BÃ¡c SÄ© LÃºa AI 4.0", page_icon="ğŸŒ¾", layout="wide")

st.markdown("""
<style>
    .main { background-color: #f4fdf4; }
    .stMetric { background-color: #ffffff; padding: 15px; border-radius: 10px; box-shadow: 0 2px 5px rgba(0,0,0,0.1); }
    .report-card { background-color: #ffffff; padding: 20px; border-radius: 15px; border-left: 8px solid #2e7d32; }
    h1 { color: #1b5e20; }
</style>
""", unsafe_allow_html=True)

# KHá»I Táº O SESSION STATE
if 'history' not in st.session_state:
    st.session_state['history'] = []
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = [
        {"role": "assistant", "content": "ğŸŒ¾ ChÃ o bÃ  con! Há»i tÃ´i vá» bá»‡nh lÃºa, thuá»‘c trá»«, kinh nghiá»‡m phun thuá»‘c..."}
    ]

# Dá»® LIá»†U Bá»†NH
DATA_BENH = {
    "Bacterial Leaf Blight": {
        "ten": "Bá»†NH Báº C LÃ (CHÃY BÃŒA LÃ)",
        "trieu_chung": "Váº¿t bá»‡nh lan dá»c mÃ©p lÃ¡ tá»« chÃ³p xuá»‘ng, mÃ u vÃ ng hoáº·c tráº¯ng xÃ¡m, rÃ¬a gá»£n sÃ³ng.",
        "nguyen_nhan": "Vi khuáº©n Xanthomonas oryzae. Thá»«a Ä‘áº¡m, mÆ°a bÃ£o lÃ m rÃ¡ch lÃ¡ lÃ¢y lan.",
        "thuoc": ["Starner 20WP", "Xanthomix 20WP", "Totan 200WP"],
        "loi_khuyen": "NgÆ°ng bÃ³n Ä‘áº¡m, bÃ³n bá»• sung Kali. RÃºt nÆ°á»›c ruá»™ng Ä‘á»ƒ háº¡n cháº¿ vi khuáº©n.",
        "icon": "ğŸ¦ "
    },
    "Blast": {
        "ten": "Bá»†NH Äáº O Ã”N (CHÃY LÃ)",
        "trieu_chung": "Váº¿t bá»‡nh hÃ¬nh máº¯t Ã©n, tÃ¢m xÃ¡m tráº¯ng, viá»n nÃ¢u Ä‘áº­m. Náº·ng cÃ³ thá»ƒ gÃ¢y chÃ¡y cáº£ lÃ¡.",
        "nguyen_nhan": "Náº¥m Pyricularia oryzae. Trá»i Ã¢m u, sÆ°Æ¡ng mÃ¹, Ä‘á»™ áº©m cao.",
        "thuoc": ["Beam 75WP", "Fuji-one 40EC", "Filia 525SE"],
        "loi_khuyen": "Giá»¯ nÆ°á»›c ruá»™ng á»•n Ä‘á»‹nh. KhÃ´ng phun phÃ¢n bÃ³n lÃ¡ khi lÃºa Ä‘ang bá»‡nh.",
        "icon": "ğŸ”¥"
    },
    "Brown Spot": {
        "ten": "Bá»†NH Äá»M NÃ‚U (TIÃŠM Lá»¬A)",
        "trieu_chung": "Váº¿t bá»‡nh trÃ²n nhá» mÃ u nÃ¢u nhÆ° háº¡t mÃ¨ ráº£i rÃ¡c trÃªn phiáº¿n lÃ¡.",
        "nguyen_nhan": "Náº¥m. ThÆ°á»ng gáº·p á»Ÿ ruá»™ng thiáº¿u dinh dÆ°á»¡ng, Ä‘áº¥t phÃ¨n, ngá»™ Ä‘á»™c há»¯u cÆ¡.",
        "thuoc": ["Tilt Super 300EC", "Anvil 5SC"],
        "loi_khuyen": "Cáº§n bÃ³n cÃ¢n Ä‘á»‘i N-P-K, bá»• sung vÃ´i Ä‘á»ƒ cáº£i táº¡o Ä‘áº¥t phÃ¨n.",
        "icon": "ğŸ‚"
    }
}
DATA_BENH.update({
    "Bacterialblight": {"ref": "Bacterial Leaf Blight"},
    "Leaf Blast": {"ref": "Blast"},
    "Rice Blast": {"ref": "Blast"},
    "Brownspot": {"ref": "Brown Spot"}
})

def lay_thoi_tiet(lat, lon):
    try:
        url = f"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&current=temperature_2m,relative_humidity_2m,rain&timezone=auto"
        return requests.get(url, timeout=5).json().get('current')
    except: 
        return None

def ve_bbox_len_anh(img, predictions):
    """Váº½ % confidence lÃªn áº£nh nhÆ° Roboflow"""
    draw = ImageDraw.Draw(img)
    try:
        font = ImageFont.truetype("/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf", 30)
    except:
        font = ImageFont.load_default()
    
    for pred in predictions[:3]:
        conf = pred['confidence'] * 100
        label = f"{pred['class']}: {conf:.1f}%"
        x, y = 20, 20 + predictions.index(pred) * 40
        bbox = draw.textbbox((x, y), label, font=font)
        draw.rectangle(bbox, fill=(0, 128, 0, 200))
        draw.text((x, y), label, fill=(255, 255, 255), font=font)
    return img

# HEADER
st.markdown("<h1>ğŸŒ¾ BÃC SÄ¨ LÃšA AI 4.0</h1>", unsafe_allow_html=True)
st.caption("Giáº£i phÃ¡p cháº©n Ä‘oÃ¡n bá»‡nh lÃºa qua hÃ¬nh áº£nh + TÆ° váº¥n AI vá»›i Gemini")

# THá»œI TIáº¾T
st.markdown("### ğŸŒ¤ï¸ Thá»i Tiáº¿t NÃ´ng Vá»¥ Thá»±c Táº¿")
loc = get_geolocation()

if loc and 'coords' in loc:
    lat, lon = loc['coords'].get('latitude'), loc['coords'].get('longitude')
    weather = lay_thoi_tiet(lat, lon)
    if weather:
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("ğŸŒ¡ï¸ Nhiá»‡t Ä‘á»™", f"{weather['temperature_2m']}Â°C")
        c2.metric("ğŸ’§ Äá»™ áº©m", f"{weather['relative_humidity_2m']}%")
        c3.metric("ğŸŒ§ï¸ MÆ°a", f"{weather['rain']} mm")
        with c4:
            if weather['rain'] > 0: 
                st.error("âš ï¸ Äang mÆ°a: Äá»«ng phun thuá»‘c!")
            elif weather['relative_humidity_2m'] > 85: 
                st.warning("ğŸ”¥ áº¨m cao: Cáº©n tháº­n Ä‘áº¡o Ã´n!")
            else: 
                st.success("ğŸŒ¤ï¸ Thá»i tiáº¿t tá»‘t")
else:
    st.info("ğŸ“ Vui lÃ²ng 'Cho phÃ©p' truy cáº­p vá»‹ trÃ­ Ä‘á»ƒ xem thá»i tiáº¿t chÃ­nh xÃ¡c táº¡i ruá»™ng")

st.markdown("---")

# TABS
tab1, tab2, tab3 = st.tabs(["ğŸ” CHáº¨N ÄOÃN HÃŒNH áº¢NH", "ğŸ’¬ TÆ¯ Váº¤N GEMINI AI", "ğŸ“‹ Lá»ŠCH Sá»¬ KHÃM"])

# TAB 1: CHáº¨N ÄOÃN
with tab1:
    col_l, col_r = st.columns([1, 1.3])
    with col_l:
        st.subheader("1. Chá»¥p áº£nh/Táº£i áº£nh lÃ¡ lÃºa")
        
        # CHá»ŒN NGUá»’N
        input_type = st.radio("Chá»n nguá»“n:", ["Táº£i áº£nh tá»« mÃ¡y", "Chá»¥p báº±ng Camera"], horizontal=True)
        
        if input_type == "Chá»¥p báº±ng Camera":
            file = st.camera_input("Chá»¥p áº£nh lÃ¡ lÃºa")
        else:
            file = st.file_uploader("Chá»n file áº£nh", type=['jpg','png','jpeg'])

    if file:
        img = Image.open(file).convert("RGB")
        with col_l:
            st.image(img, use_column_width=True, caption="Máº«u bá»‡nh Ä‘áº§u vÃ o")
            
            if st.button("ğŸš€ Báº®T Äáº¦U CHáº¨N ÄOÃN", type="primary", use_container_width=True):
                with col_r:
                    with st.spinner("AI Ä‘ang phÃ¢n tÃ­ch tá»« model Roboflow cá»§a báº¡n..."):
                        img.save("process.jpg")
                        
                        # Gá»ŒI ROBOFLOW MODEL
                        client = InferenceHTTPClient(
                            api_url="https://detect.roboflow.com", 
                            api_key="8tf2UvcnEv8h80bV2G0Q"
                        )
                        res = client.infer("process.jpg", model_id="rice-leaf-disease-twtlz/1")
                        preds = res.get('predictions', [])
                        
                        if isinstance(preds, dict): 
                            preds = [{"class": k, "confidence": v['confidence']} for k, v in preds.items()]

                        if preds:
                            # TOP 3
                            top3 = sorted(preds, key=lambda x: x['confidence'], reverse=True)[:3]
                            
                            # Váº¼ % LÃŠN áº¢NH
                            img_annotated = ve_bbox_len_anh(img.copy(), top3)
                            st.image(img_annotated, caption="Káº¿t quáº£ AI vá»›i % Confidence")
                            
                            # HIá»‚N THá»Š METRIC TOP 3
                            st.subheader("ğŸ“Š Äá»™ tin cáº­y tá»« Model Roboflow")
                            c1, c2, c3 = st.columns(3)
                            for i, pred in enumerate(top3):
                                with [c1, c2, c3][i]:
                                    emoji = "ğŸŸ¢" if i==0 else "ğŸŸ¡" if i==1 else "ğŸŸ "
                                    st.metric(f"{emoji} {pred['class']}", f"{pred['confidence']*100:.1f}%")
                            
                            # THÃ”NG TIN Bá»†NH TOP 1
                            top = top3[0]
                            benh = DATA_BENH.get(top['class'])
                            if benh and "ref" in benh: 
                                benh = DATA_BENH.get(benh["ref"])
                            
                            if benh:
                                st.markdown(f"### âœ… Káº¿t luáº­n: {benh['ten']} ({top['confidence']*100:.1f}%)")
                                st.markdown(f"""
                                <div class="report-card">
                                    <p><b>ğŸ§ Dáº¥u hiá»‡u:</b> {benh.get('trieu_chung','ChÆ°a cÃ³ dá»¯ liá»‡u')}</p>
                                    <p><b>ğŸŒªï¸ NguyÃªn nhÃ¢n:</b> {benh.get('nguyen_nhan','ChÆ°a cÃ³ dá»¯ liá»‡u')}</p>
                                    <p style="color: #d32f2f;"><b>ğŸ’Š Thuá»‘c Ä‘áº·c trá»‹:</b> {', '.join(benh['thuoc'])}</p>
                                    <p><b>ğŸ’¡ Lá»i khuyÃªn:</b> {benh.get('loi_khuyen','')}</p>
                                </div>
                                """, unsafe_allow_html=True)
                                
                                # GIá»ŒNG NÃ“I
                                txt_read = f"LÃºa bá»‹ {benh['ten']}. BÃ  con dÃ¹ng thuá»‘c {benh['thuoc'][0]}."
                                gTTS(txt_read, lang='vi').save("voice.mp3")
                                st.audio("voice.mp3")
                                
                                # LÆ¯U Lá»ŠCH Sá»¬
                                st.session_state.history.append({
                                    "time": datetime.now().strftime("%H:%M"),
                                    "benh": benh['ten'],
                                    "conf": top['confidence']*100
                                })
                        else:
                            st.success("ğŸŒ¿ CÃ¢y lÃºa khá»e máº¡nh! ChÃºc má»«ng bÃ  con.")

# TAB 2: CHATBOT GEMINI
with tab2:
    st.subheader("ğŸ’¬ Há»i Ä‘Ã¡p cÃ¹ng chuyÃªn gia Gemini AI")
    
    # Hiá»ƒn thá»‹ lá»‹ch sá»­ chat
    for msg in st.session_state.chat_history:
        with st.chat_message(msg["role"]):
            st.write(msg["content"])
    
    # Input cÃ¢u há»i
    if prompt := st.chat_input("Há»i vá» bá»‡nh lÃºa, thuá»‘c trá»«, kinh nghiá»‡m phun thuá»‘c..."):
        st.session_state.chat_history.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.write(prompt)
        
        # Gá»ŒI GEMINI
        with st.spinner("Gemini Ä‘ang tráº£ lá»i..."):
            system_prompt = f"""Báº¡n lÃ  chuyÃªn gia nÃ´ng nghiá»‡p Viá»‡t Nam, chuyÃªn sÃ¢u vá» bá»‡nh lÃºa vÃ  cÃ¢y trá»“ng.
Tráº£ lá»i ngáº¯n gá»n, thá»±c táº¿, dá»… hiá»ƒu cho nÃ´ng dÃ¢n. Táº­p trung vÃ o:
- TÃªn bá»‡nh, triá»‡u chá»©ng
- Thuá»‘c trá»« bá»‡nh cá»¥ thá»ƒ (tÃªn thÆ°Æ¡ng máº¡i + hoáº¡t cháº¥t)
- CÃ¡ch phÃ²ng bá»‡nh, thá»i Ä‘iá»ƒm phun
- Kinh nghiá»‡m thá»±c táº¿

CÃ¢u há»i cá»§a nÃ´ng dÃ¢n: {prompt}"""
            
            try:
                response = model.generate_content(system_prompt)
                reply = response.text
            except Exception as e:
                reply = f"âš ï¸ Lá»—i káº¿t ná»‘i Gemini: {str(e)}. Vui lÃ²ng kiá»ƒm tra API key hoáº·c thá»­ láº¡i."
        
        st.session_state.chat_history.append({"role": "assistant", "content": reply})
        with st.chat_message("assistant"):
            st.write(reply)

# TAB 3: Lá»ŠCH Sá»¬
with tab3:
    st.subheader("ğŸ“‹ Lá»‹ch sá»­ cháº©n Ä‘oÃ¡n trong ngÃ y")
    if st.session_state.history:
        for h in reversed(st.session_state.history):
            st.write(f"â° {h['time']} - PhÃ¡t hiá»‡n: **{h['benh']}** ({h['conf']:.1f}%)")
    else:
        st.write("ChÆ°a cÃ³ lÆ°á»£t khÃ¡m nÃ o.")
