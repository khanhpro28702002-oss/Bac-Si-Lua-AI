import streamlit as st
import requests
from inference_sdk import InferenceHTTPClient
from PIL import Image
import os

# ==========================================
# 1. Cáº¤U HÃŒNH HUGGING FACE (Bá»˜ NÃƒO AI)
# ==========================================
# DÃN MÃƒ TOKEN Cá»¦A Báº N VÃ€O GIá»®A Dáº¤U NGOáº¶C KÃ‰P
HF_TOKEN = "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"  # âš ï¸ QUAN TRá»ŒNG: Thay token má»›i sau khi revoke token cÅ©
# MÃ´ hÃ¬nh Qwen2.5 há»— trá»£ tiáº¿ng Viá»‡t ráº¥t tá»‘t
MODEL_URL = "https://api-inference.huggingface.co/models/Qwen/Qwen2.5-7B-Instruct"

def goi_chuyen_gia_hf(user_input):
    headers = {"Authorization": f"Bearer {HF_TOKEN}"}
    # Cáº¥u hÃ¬nh lá»i nháº¯c (Prompt) Ä‘á»ƒ AI Ä‘Ã³ng vai chuyÃªn gia
    system_prompt = f"<|im_start|>system\nBáº¡n lÃ  chuyÃªn gia nÃ´ng nghiá»‡p Viá»‡t Nam. HÃ£y tÆ° váº¥n cho nÃ´ng dÃ¢n ngáº¯n gá»n, dá»… hiá»ƒu.<|im_end|>\n<|im_start|>user\n{user_input}<|im_end|>\n<|im_start|>assistant\n"
    
    payload = {
        "inputs": system_prompt,
        "parameters": {"max_new_tokens": 512, "temperature": 0.7}
    }
    
    try:
        response = requests.post(MODEL_URL, headers=headers, json=payload, timeout=30)
        response.raise_for_status()  # Kiá»ƒm tra lá»—i HTTP
        result = response.json()
        # Xá»­ lÃ½ vÄƒn báº£n tráº£ vá»
        if isinstance(result, list) and len(result) > 0:
            text = result[0].get('generated_text', '')
            return text.split("<|im_start|>assistant\n")[-1].strip()
        else:
            return "KhÃ´ng nháº­n Ä‘Æ°á»£c pháº£n há»“i tá»« AI. Vui lÃ²ng thá»­ láº¡i."
    except Exception as e:
        return f"Dáº¡, chuyÃªn gia AI Ä‘ang báº­n tÃ­ (Lá»—i: {str(e)}). BÃ  con thá»­ láº¡i sau nhÃ©!"

# ==========================================
# 2. GIAO DIá»†N CHÃNH
# ==========================================
st.set_page_config(page_title="BÃ¡c SÄ© LÃºa AI Pro", layout="wide")
st.markdown("<h1 style='color: #2e7d32;'>ğŸŒ¾ BÃC SÄ¨ LÃšA AI: HUGGING FACE EDITION</h1>", unsafe_allow_html=True)

# âœ… Sá»¬A Lá»–I: Loáº¡i bá» get_geolocation() Ä‘á»ƒ trÃ¡nh lá»—i
# Náº¿u muá»‘n GPS, cÃ i: pip install streamlit-js-eval
# NhÆ°ng Ä‘á»ƒ Ä‘Æ¡n giáº£n, tÃ´i táº¯t tÃ­nh nÄƒng nÃ y
st.info("ğŸ“Œ á»¨ng dá»¥ng cháº©n Ä‘oÃ¡n bá»‡nh lÃºa vÃ  tÆ° váº¥n nÃ´ng nghiá»‡p")

st.markdown("---")
tab1, tab2 = st.tabs(["ğŸ“¸ CHáº¨N ÄOÃN áº¢NH", "ğŸ’¬ CHUYÃŠN GIA AI"])

# --- TAB CHáº¨N ÄOÃN (Sá»­ dá»¥ng Roboflow) ---
with tab1:
    f = st.file_uploader("Chá»n áº£nh lÃ¡ lÃºa bá»‹ bá»‡nh", type=['jpg','png','jpeg'])
    if f:
        img = Image.open(f)
        st.image(img, use_column_width=True)
        if st.button("ğŸ” PHÃ‚N TÃCH Bá»†NH", type="primary"):
            with st.spinner("Äang soi bá»‡nh..."):
                try:
                    # LÆ°u áº£nh táº¡m
                    img.save("temp.jpg")
                    # Roboflow API
                    client = InferenceHTTPClient(
                        api_url="https://detect.roboflow.com", 
                        api_key="8tf2UvcnEv8h80bV2G0Q"
                    )
                    res = client.infer("temp.jpg", model_id="rice-leaf-disease-twtlz/1")
                    preds = res.get('predictions', [])
                    
                    if preds:
                        benh = preds[0]['class']
                        confidence = preds[0].get('confidence', 0) * 100
                        st.error(f"âš ï¸ PhÃ¡t hiá»‡n: **{benh}** (Äá»™ tin cáº­y: {confidence:.1f}%)")
                        
                        # DÃ¹ng Hugging Face Ä‘á»ƒ tÆ° váº¥n phÃ¡c Ä‘á»“
                        st.write("ğŸ¤– **TÆ° váº¥n tá»« AI:**")
                        advice = goi_chuyen_gia_hf(f"LÃºa bá»‹ bá»‡nh {benh}. HÃ£y cho biáº¿t tÃªn tiáº¿ng Viá»‡t vÃ  thuá»‘c Ä‘áº·c trá»‹ cá»¥ thá»ƒ.")
                        st.write(advice)
                    else:
                        st.success("âœ… CÃ¢y lÃºa khá»e máº¡nh!")
                    
                    # XÃ³a file táº¡m
                    if os.path.exists("temp.jpg"):
                        os.remove("temp.jpg")
                        
                except Exception as e:
                    st.error(f"Lá»—i phÃ¢n tÃ­ch: {str(e)}")

# --- TAB CHATBOT AI ---
with tab2:
    st.write("ğŸ’¡ **Há»i báº¥t ká»³ cÃ¢u há»i nÃ o vá» trá»“ng lÃºa, chÄƒm sÃ³c cÃ¢y, dinh dÆ°á»¡ng...**")
    
    # Khá»Ÿi táº¡o lá»‹ch sá»­ chat
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    # Hiá»ƒn thá»‹ lá»‹ch sá»­ chat
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])
    
    # Input chat
    if query := st.chat_input("Há»i chuyÃªn gia vá» ká»¹ thuáº­t lÃºa gáº¡o..."):
        # Hiá»ƒn thá»‹ cÃ¢u há»i
        st.session_state.messages.append({"role": "user", "content": query})
        with st.chat_message("user"):
            st.write(query)
        
        # Láº¥y cÃ¢u tráº£ lá»i tá»« AI
        with st.chat_message("assistant"):
            with st.spinner("Äang suy luáº­n..."):
                response = goi_chuyen_gia_hf(query)
                st.write(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
