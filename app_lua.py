import streamlit as st
from inference_sdk import InferenceHTTPClient
from PIL import Image
import numpy as np
import cv2
from datetime import datetime
from gtts import gTTS
import io
from fpdf import FPDF
import requests
from streamlit_js_eval import get_geolocation
import google.generativeai as genai

# ==============================================================================
# 1. C·∫§U H√åNH H·ªÜ TH·ªêNG & AI BRAIN (GEMINI)
# ==============================================================================

# THAY M√É API KEY C·ª¶A B·∫†N V√ÄO ƒê√ÇY
API_KEY_GEMINI = "AIzaSyBFYtJFvAAiR3DqqcNtw1-3gHHe2g-2eXA"

# C·∫•u h√¨nh "Nh√¢n c√°ch" cho Tr·ª£ l√Ω AI
genai.configure(api_key=API_KEY_GEMINI)
model_gemini = genai.GenerativeModel(
    model_name="gemini-1.5-flash",
    system_instruction=(
        "B·∫°n l√† Chuy√™n gia N√¥ng nghi·ªáp Vi·ªát Nam v·ªõi 30 nƒÉm kinh nghi·ªám v·ªÅ l√∫a g·∫°o. "
        "H√£y d√πng gi·ªçng vƒÉn g·∫ßn g≈©i, ch√¢n ch·∫•t c·ªßa ng∆∞·ªùi mi·ªÅn T√¢y ho·∫∑c mi·ªÅn B·∫Øc ƒë·ªÉ t∆∞ v·∫•n cho b√† con. "
        "Ki·∫øn th·ª©c c·ªßa b·∫°n bao g·ªìm: k·ªπ thu·∫≠t canh t√°c, nh·∫≠n bi·∫øt s√¢u b·ªánh, c√°ch d√πng thu·ªëc BVTV an to√†n, "
        "v√† qu·∫£n l√Ω n∆∞·ªõc ru·ªông. N·∫øu b√† con h·ªèi v·ªÅ b·ªánh l√∫a, h√£y t∆∞ v·∫•n chi ti·∫øt ph√°c ƒë·ªì ƒëi·ªÅu tr·ªã."
    )
)

# C·∫•u h√¨nh Roboflow (Th·ªã gi√°c m√°y t√≠nh)
ROBO_API_KEY = "8tf2UvcnEv8h80bV2G0Q"
MODEL_ID = "rice-leaf-disease-twtlz/1"

st.set_page_config(page_title="B√°c Sƒ© L√∫a AI Pro", page_icon="üåæ", layout="wide")

# Kh·ªüi t·∫°o b·ªô nh·ªõ Chat
if 'chat_history' not in st.session_state:
    st.session_state['chat_history'] = []

# ==============================================================================
# 2. C√ÅC H√ÄM X·ª¨ L√ù (H√ÄM CON)
# ==============================================================================

def get_weather(lat, lon):
    try:
        url = f"https://api.open-meteo.com/v1/forecast?latitude={lat}&longitude={lon}&current=temperature_2m,relative_humidity_2m,rain&timezone=auto"
        return requests.get(url, timeout=5).json().get('current')
    except: return None

def create_pdf(info_text):
    pdf = FPDF()
    pdf.add_page()
    pdf.set_font("Arial", size=14)
    pdf.cell(200, 10, txt="PHIEU KET QUA TU VAN NONG NGHIEP", ln=1, align='C')
    pdf.ln(10)
    pdf.multi_cell(0, 10, txt=info_text.encode('latin-1', 'ignore').decode('latin-1'))
    return pdf.output(dest='S').encode('latin-1', 'ignore')

# ==============================================================================
# 3. GIAO DI·ªÜN NG∆Ø·ªúI D√ôNG (UI)
# ==============================================================================

st.markdown("<h1 style='color: #1b5e20;'>üåæ B√ÅC Sƒ® L√öA AI: SI√äU TR·ª¢ L√ù 4.0</h1>", unsafe_allow_html=True)

# --- PH·∫¶N TH·ªúI TI·∫æT ---
st.subheader("üå¶Ô∏è Th·ªùi Ti·∫øt N√¥ng V·ª•")
loc = get_geolocation()
if loc and 'coords' in loc:
    lat, lon = loc['coords']['latitude'], loc['coords']['longitude']
    w = get_weather(lat, lon)
    if w:
        c1, c2, c3 = st.columns(3)
        c1.metric("üå°Ô∏è Nhi·ªát ƒë·ªô", f"{w['temperature_2m']}¬∞C")
        c2.metric("üíß ƒê·ªô ·∫©m", f"{w['relative_humidity_2m']}%")
        c3.metric("üåßÔ∏è L∆∞·ª£ng m∆∞a", f"{w['rain']} mm")
        if w['rain'] > 0: st.error("‚òî ƒêang c√≥ m∆∞a: B√† con t·∫°m ng∆∞ng phun thu·ªëc!")
else:
    st.info("üìç ƒêang ch·ªù v·ªã tr√≠ GPS ƒë·ªÉ d·ª± b√°o th·ªùi ti·∫øt t·∫°i ru·ªông...")

st.markdown("---")

# --- TAB CH·ª®C NƒÇNG ---
tab_camera, tab_chat = st.tabs(["üì∏ CH·∫®N ƒêO√ÅN H√åNH ·∫¢NH", "üí¨ H·ªéI ƒê√ÅP CHUY√äN GIA AI"])

# --- TAB 1: CAMERA AI ---
with tab_camera:
    col_l, col_r = st.columns([1, 1.2])
    with col_l:
        mode = st.radio("Ch·ªçn ngu·ªìn ·∫£nh:", ["T·∫£i l√™n", "Ch·ª•p tr·ª±c ti·∫øp"], horizontal=True)
        input_file = st.camera_input("Ch·ª•p l√° l√∫a") if mode == "Ch·ª•p tr·ª±c ti·∫øp" else st.file_uploader("Ch·ªçn ·∫£nh", type=['jpg','png'])

    if input_file:
        img = Image.open(input_file)
        with col_l:
            st.image(img, use_column_width=True)
            if st.button("üîç PH√ÇN T√çCH M·∫™U B·ªÜNH", type="primary", use_container_width=True):
                with col_r:
                    with st.spinner("AI ƒëang soi b·ªánh..."):
                        img.save("temp.jpg")
                        client = InferenceHTTPClient(api_url="https://detect.roboflow.com", api_key=ROBO_API_KEY)
                        res = client.infer("temp.jpg", model_id=MODEL_ID)
                        preds = res.get('predictions', [])
                        
                        if preds:
                            # N·∫øu c√≥ b·ªánh, d√πng Gemini ƒë·ªÉ gi·∫£i th√≠ch chi ti·∫øt
                            top_label = preds[0]['class'] if isinstance(preds, list) else list(preds.keys())[0]
                            st.warning(f"‚ö†Ô∏è Ph√°t hi·ªán d·∫•u hi·ªáu: {top_label}")
                            
                            # D√πng "N√£o b·ªô" Gemini ƒë·ªÉ t∆∞ v·∫•n chi ti·∫øt v·ªÅ b·ªánh n√†y
                            prompt_advice = f"L√° l√∫a c√≥ d·∫•u hi·ªáu b·ªánh {top_label}. H√£y cho bi·∫øt t√™n ti·∫øng Vi·ªát, tri·ªáu ch·ª©ng chi ti·∫øt, nguy√™n nh√¢n v√† danh s√°ch c√°c lo·∫°i thu·ªëc BVTV ƒë·∫∑c tr·ªã t·∫°i Vi·ªát Nam k√®m c√°ch d√πng."
                            advice = model_gemini.generate_content(prompt_advice).text
                            
                            st.markdown("### üìã T∆∞ v·∫•n t·ª´ Chuy√™n gia:")
                            st.write(advice)
                            
                            # Gi·ªçng n√≥i
                            gTTS(f"Ph√°t hi·ªán b·ªánh {top_label}. B√† con xem h∆∞·ªõng d·∫´n ƒëi·ªÅu tr·ªã b√™n d∆∞·ªõi.", lang='vi').save("v.mp3")
                            st.audio("v.mp3")
                            
                            # PDF
                            st.download_button("üì• T·∫£i h∆∞·ªõng d·∫´n ƒëi·ªÅu tr·ªã (PDF)", create_pdf(advice), "Tu_van_lua.pdf")
                        else:
                            st.success("‚úÖ C√¢y l√∫a kh·ªèe m·∫°nh! Ti·∫øp t·ª•c theo d√µi b√† con nh√©.")

# --- TAB 2: CHATBOT TH√îNG MINH (GEMINI) ---
with tab_chat:
    st.subheader("üí¨ Tr√≤ chuy·ªán c√πng Chuy√™n gia N√¥ng nghi·ªáp")
    st.caption("B√† con c√≥ th·ªÉ h·ªèi b·∫•t c·ª© ƒëi·ªÅu g√¨: k·ªπ thu·∫≠t b√≥n ph√¢n, c√°ch tr·ªã r·∫ßy n√¢u, gi·ªëng l√∫a ST25...")

    # Hi·ªÉn th·ªã l·ªãch s·ª≠ chat
    for m in st.session_state.chat_history:
        with st.chat_message(m["role"]): st.write(m["content"])

    # Nh·∫≠p c√¢u h·ªèi
    if user_p := st.chat_input("Nh·∫≠p c√¢u h·ªèi t·∫°i ƒë√¢y..."):
        st.session_state.chat_history.append({"role": "user", "content": user_p})
        with st.chat_message("user"): st.write(user_p)
        
        with st.chat_message("assistant"):
            with st.spinner("Chuy√™n gia ƒëang suy nghƒ©..."):
                try:
                    # G·ª≠i c√¢u h·ªèi cho Gemini
                    response = model_gemini.generate_content(user_p)
                    full_reply = response.text
                    st.write(full_reply)
                    st.session_state.chat_history.append({"role": "assistant", "content": full_reply})
                except Exception as e:
                    st.error("D·∫°, m·∫°ng h∆°i y·∫øu b√† con ƒë·ª£i x√≠u ·∫°!")
import streamlit as st
import google.generativeai as genai
from inference_sdk import InferenceHTTPClient
from PIL import Image
import requests
from streamlit_js_eval import get_geolocation

# --- C·∫§U H√åNH ---
# D√ÅN API KEY C·ª¶A B·∫†N V√ÄO ƒê√ÇY
GEMINI_KEY = "AIzaSyBFYtJFvAAiR3DqqcNtw1-3gHHe2g-2eXA"

# Kh·ªüi t·∫°o Gemini
genai.configure(api_key=GEMINI_KEY)
model = genai.GenerativeModel('gemini-1.5-flash')

st.set_page_config(page_title="B√°c Sƒ© L√∫a Pro", layout="wide")

# Ki·ªÉm tra GPS an to√†n ƒë·ªÉ kh√¥ng b·ªã KeyError
st.subheader("üå¶Ô∏è Th·ªùi Ti·∫øt T·∫°i Ru·ªông")
loc = get_geolocation()
if loc and 'coords' in loc:
    lat = loc['coords'].get('latitude')
    lon = loc['coords'].get('longitude')
    if lat and lon:
        st.success(f"üìç ƒê√£ x√°c ƒë·ªãnh v·ªã tr√≠: {lat}, {lon}")
        # (Ph·∫ßn g·ªçi API th·ªùi ti·∫øt ·ªü ƒë√¢y...)
else:
    st.info("üìå B√† con vui l√≤ng b·∫•m 'Cho ph√©p' truy c·∫≠p v·ªã tr√≠ ƒë·ªÉ xem th·ªùi ti·∫øt nh√©.")

st.markdown("---")

# --- PH·∫¶N CHAT TH√îNG MINH ---
st.subheader("üí¨ Tr√≤ chuy·ªán c√πng Chuy√™n gia AI")
if 'chat_history' not in st.session_state:
    st.session_state['chat_history'] = []

for m in st.session_state.chat_history:
    with st.chat_message(m["role"]): st.write(m["content"])

if p := st.chat_input("H·ªèi g√¨ ƒëi b√† con..."):
    st.session_state.chat_history.append({"role": "user", "content": p})
    with st.chat_message("user"): st.write(p)
    
    with st.chat_message("assistant"):
        try:
            # ƒê√¢y l√† n∆°i g·ªçi b·ªô n√£o Gemini th·ª±c s·ª±
            response = model.generate_content(p)
            st.write(response.text)
            st.session_state.chat_history.append({"role": "assistant", "content": response.text})
        except Exception as e:
            st.error(f"L·ªói k·∫øt n·ªëi AI: {e}")